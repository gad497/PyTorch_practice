{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1866ad62-f96e-4939-b5ca-16c2e16aeff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.transforms.v2 import PILToTensor, ToDtype\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b255291-4744-4aae-9c74-0702efefcb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: data\\CIFAR10\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               PILToTensor()\n",
      "               ToDtype(scale=False)\n",
      "           ) Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\\CIFAR10\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               PILToTensor()\n",
      "               ToDtype(scale=False)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "data_path = Path(\"data\")\n",
    "image_path = data_path / \"CIFAR10\"\n",
    "image_transform = torchvision.transforms.Compose([PILToTensor(),\n",
    "                                                 ToDtype(torch.float32)])\n",
    "train_data = torchvision.datasets.CIFAR10(root=image_path,\n",
    "                                         train=True,\n",
    "                                         download=True,\n",
    "                                         transform=image_transform)\n",
    "test_data = torchvision.datasets.CIFAR10(root=image_path,\n",
    "                                         train=False,\n",
    "                                         download=True,\n",
    "                                        transform=image_transform)\n",
    "print(train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6d95809-15c4-4248-8475-fb911af876f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002180A330610> <torch.utils.data.dataloader.DataLoader object at 0x000002180A330BB0>\n",
      "Train dataloader lenght: 1563\n",
      "Test dataloader lenght: 313\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              shuffle=True,\n",
    "                              num_workers=NUM_WORKERS)\n",
    "test_dataloader = DataLoader(dataset=test_data,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=False,\n",
    "                             num_workers=NUM_WORKERS)\n",
    "print(train_dataloader, test_dataloader)\n",
    "print(f\"Train dataloader lenght: {len(train_dataloader)}\\nTest dataloader lenght: {len(test_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6478c775-ef3c-44eb-af19-32bc40bfe4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 32, 32])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(train_dataloader))\n",
    "image_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fb250f0c-3c37-497b-8e34-fd8a81799c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['airplane',\n",
       "  'automobile',\n",
       "  'bird',\n",
       "  'cat',\n",
       "  'deer',\n",
       "  'dog',\n",
       "  'frog',\n",
       "  'horse',\n",
       "  'ship',\n",
       "  'truck'],\n",
       " torch.float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.classes, image_batch.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0335fe5-1953-43f3-927c-1f5d9da78448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self, input_size: int, hidden_units: int, output_size: int):\n",
    "        super().__init__()\n",
    "        self.conv_layer_1 = nn.Sequential(nn.Conv2d(in_channels=input_size,\n",
    "                                                    out_channels=hidden_units,\n",
    "                                                    kernel_size=3,\n",
    "                                                    padding=0,\n",
    "                                                    stride=1),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Conv2d(in_channels=hidden_units,\n",
    "                                                    out_channels=hidden_units,\n",
    "                                                    kernel_size=3,\n",
    "                                                    padding=0,\n",
    "                                                    stride=1),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.MaxPool2d(kernel_size=2,\n",
    "                                                       stride=1))\n",
    "        self.conv_layer_2 = nn.Sequential(nn.Conv2d(in_channels=hidden_units,\n",
    "                                                    out_channels=hidden_units,\n",
    "                                                    kernel_size=3,\n",
    "                                                    padding=0,\n",
    "                                                    stride=1),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Conv2d(in_channels=hidden_units,\n",
    "                                                    out_channels=hidden_units,\n",
    "                                                    kernel_size=3,\n",
    "                                                    padding=0,\n",
    "                                                    stride=1),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.MaxPool2d(kernel_size=2,\n",
    "                                                       stride=1))\n",
    "        self.linear_layer = nn.Sequential(nn.Flatten(),\n",
    "                                          nn.Linear(in_features=hidden_units*22*22,\n",
    "                                                    out_features=output_size))\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.linear_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f971d93-d084-445e-bfd8-01f50108ea37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyVGG(\n",
       "  (conv_layer_1): Sequential(\n",
       "    (0): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv_layer_2): Sequential(\n",
       "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (3): ReLU()\n",
       "    (4): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (linear_layer): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=4840, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = TinyVGG(input_size = 3, hidden_units = 10, output_size = len(train_data.classes))\n",
    "model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "809c7445-366c-4440-a21c-f8627641187d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.9263e-02, -5.7457e-01, -3.8242e-02,  1.8610e-01, -2.0569e-01,\n",
       "         -3.6785e-01, -1.3927e-01, -2.5597e-01,  1.6878e-01,  5.2950e-01],\n",
       "        [-2.5418e-01, -2.2228e-01, -1.9802e-01,  2.6527e-01, -5.2416e-01,\n",
       "          8.9739e-02, -2.7519e-01,  7.6876e-01,  1.5915e-01,  1.7891e-01],\n",
       "        [-3.8404e-01, -2.7174e-01,  2.5367e-01,  2.0262e-01, -8.8375e-01,\n",
       "         -6.4694e-01,  1.2264e-01, -1.5233e-01, -1.2184e-01,  1.0719e+00],\n",
       "        [-1.4112e-01, -5.0311e-01, -5.8862e-01,  1.2111e-01, -1.3987e-01,\n",
       "         -3.5381e-01, -4.1576e-01, -6.7284e-01,  3.0174e-01,  4.2602e-01],\n",
       "        [-5.9583e-01, -8.2177e-01, -4.5160e-01,  4.3052e-01, -4.9938e-01,\n",
       "         -9.0416e-01, -7.8124e-01, -8.7375e-02,  1.0801e-01,  2.7711e-01],\n",
       "        [-6.2233e-01, -1.0075e+00, -4.1872e-01,  2.4204e-01, -7.8757e-01,\n",
       "         -6.6359e-01, -5.8333e-01, -3.9064e-01,  2.6214e-01,  6.0758e-01],\n",
       "        [-4.5958e-02, -1.9159e-01, -2.8046e-01, -9.4460e-02, -6.5996e-02,\n",
       "         -3.7428e-01, -2.7937e-01, -5.0337e-01,  1.1400e-02, -5.1473e-03],\n",
       "        [-2.7807e-01, -7.2570e-01, -2.5838e-01,  1.5862e-01, -6.6765e-01,\n",
       "         -4.5149e-01, -4.6658e-01, -5.9118e-01,  5.0372e-01,  7.3550e-01],\n",
       "        [-1.7207e-01, -7.8316e-01, -2.4409e-01,  4.1537e-01, -8.5740e-02,\n",
       "         -6.2734e-01, -6.0748e-01, -2.7950e-01, -4.9941e-02,  5.8567e-01],\n",
       "        [-3.0124e-01, -1.6548e-01, -8.1853e-01,  1.6822e-01, -1.7158e-01,\n",
       "         -4.8880e-01, -4.8189e-01, -5.6371e-01,  7.2234e-01,  4.5381e-01],\n",
       "        [ 1.8496e-01, -6.7114e-01, -8.2531e-01, -3.9924e-01, -3.9829e-01,\n",
       "         -1.3436e+00, -6.6345e-01, -3.7790e-01,  2.5465e-01, -7.1652e-02],\n",
       "        [-2.7115e-01, -6.2549e-01, -5.6214e-01,  3.6367e-02,  1.9981e-01,\n",
       "          1.7339e-01, -5.3422e-01, -7.8922e-01,  7.4099e-01,  8.4345e-01],\n",
       "        [-7.4527e-01, -6.1032e-01, -5.2149e-01,  6.7329e-01, -4.2419e-01,\n",
       "         -3.5541e-01, -1.6673e-01, -1.8306e-01,  3.9280e-01,  4.9995e-01],\n",
       "        [ 1.0571e-01, -5.7596e-01, -1.1906e-01,  1.9488e-01, -7.5145e-01,\n",
       "         -5.2052e-01, -1.1149e-01, -2.1093e-01,  2.6204e-01,  2.2453e-01],\n",
       "        [-1.0946e-01, -1.0841e+00, -3.4922e-01,  4.6589e-01, -7.8354e-01,\n",
       "         -9.7302e-01, -3.8822e-01, -7.9547e-01,  8.2186e-03,  8.2908e-01],\n",
       "        [-4.8169e-01, -2.3531e-01, -2.7825e-02,  3.5302e-01, -5.9829e-01,\n",
       "         -6.2295e-01, -3.1268e-01, -1.0569e-01,  1.2093e-01,  8.3482e-01],\n",
       "        [-6.3486e-01, -8.5363e-01, -5.4788e-01,  3.8715e-01, -5.7078e-01,\n",
       "         -7.9491e-01, -3.5243e-01, -2.3467e-01,  2.1413e-01,  8.9779e-01],\n",
       "        [-1.7769e-01, -1.7933e-01, -1.8703e-01,  4.7173e-02, -7.7552e-03,\n",
       "         -3.4228e-01, -2.6825e-01, -3.8427e-01, -5.0971e-01,  3.7640e-01],\n",
       "        [-8.2014e-01, -5.0608e-01, -3.5542e-01, -2.4150e-01,  1.5129e-01,\n",
       "         -3.6657e-01, -7.5002e-01, -3.4933e-01,  1.5026e-01,  7.4140e-01],\n",
       "        [-2.5895e-01, -7.0213e-01, -3.0507e-01,  3.0172e-01, -2.8161e-01,\n",
       "         -3.9265e-01, -1.4237e-01, -2.8063e-02,  5.7411e-01,  9.0860e-01],\n",
       "        [-1.0320e-01, -6.0589e-01, -5.4978e-01, -3.6037e-03,  4.5153e-01,\n",
       "         -5.4375e-01, -5.0030e-01, -6.9778e-01,  3.3363e-01,  5.0977e-01],\n",
       "        [-5.0057e-01, -6.5588e-01,  4.9088e-02,  2.5550e-01, -3.5260e-01,\n",
       "         -4.0711e-01, -4.6654e-01, -3.9214e-01,  2.9403e-01,  7.0344e-01],\n",
       "        [-5.7925e-01, -1.0584e+00, -4.8215e-01, -1.1615e-01, -8.8348e-01,\n",
       "         -6.6200e-01, -1.4848e-01, -3.8765e-01, -2.9109e-01,  9.7644e-01],\n",
       "        [ 9.6475e-02, -1.7259e-01, -5.1738e-01,  8.3443e-03, -3.3202e-01,\n",
       "         -5.7586e-01, -7.7086e-01,  8.1749e-02,  4.8955e-01,  3.9099e-01],\n",
       "        [ 2.5240e-01, -4.8420e-01, -6.2508e-01, -7.8035e-01, -4.4888e-01,\n",
       "         -1.9854e-01, -6.6433e-01, -5.2630e-01, -9.4878e-02,  5.8626e-02],\n",
       "        [ 5.2053e-05, -1.9766e-01, -1.2273e-01, -1.2665e-01,  7.2816e-02,\n",
       "         -1.0444e-01, -5.3993e-01, -2.5750e-01,  1.6999e-02,  5.8552e-02],\n",
       "        [-1.8046e-01, -1.3126e+00, -2.3501e-01,  6.8345e-02, -6.2971e-01,\n",
       "         -9.3628e-01, -7.6830e-01, -4.7798e-01,  1.9426e-01,  7.7493e-01],\n",
       "        [-2.6044e-01, -8.4681e-01, -3.9362e-01, -1.7458e-01,  2.6876e-01,\n",
       "         -8.7734e-03,  6.7039e-02, -6.3341e-01,  5.4898e-01,  4.7238e-01],\n",
       "        [-4.2766e-01, -9.1064e-02, -4.1160e-02,  3.7857e-02,  2.8622e-02,\n",
       "         -2.7547e-01,  2.1217e-02, -3.6155e-01, -2.9848e-01,  1.3209e-01],\n",
       "        [-2.4635e-01, -1.0656e+00, -1.0168e-01,  3.9312e-01, -7.0325e-01,\n",
       "         -5.1628e-01, -2.0874e-01,  3.8047e-02,  2.0061e-01,  1.2574e+00],\n",
       "        [-2.9651e-01, -1.5288e-01, -3.9489e-01,  8.9331e-02, -2.9150e-01,\n",
       "         -6.6755e-01, -5.4350e-01, -6.1536e-01,  5.5570e-01,  4.8565e-01],\n",
       "        [ 8.7468e-02, -1.1759e+00, -2.2197e-01, -4.4292e-01, -7.3272e-01,\n",
       "         -4.2591e-01, -1.6570e-01,  8.6360e-02, -2.5577e-01,  7.2479e-01]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(image_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bcea758a-fb8d-42e0-8684-828f18993a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pass(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer) -> torch.Tensor:\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch,(X,y) in enumerate(dataloader):\n",
    "        y_preds = model(X)\n",
    "        loss = loss_fn(y_preds,y)\n",
    "        train_loss += loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    train_loss = train_loss/len(dataloader)\n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cd7e84d-786f-4337-9d7c-8c918fd43a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(17.5978, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pass(model1, [(image_batch, label_batch)], nn.CrossEntropyLoss(), torch.optim.SGD(params=model1.parameters(), lr=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac024c38-76e6-400e-ae0c-6ed7f07d4409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3c861-d37a-4301-8687-78729948158a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python pytorch",
   "language": "python",
   "name": "venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
